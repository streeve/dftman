{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python stdlib imports\n",
    "import sys\n",
    "import qgrid\n",
    "import copy\n",
    "\n",
    "# Module imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymatgen import Structure\n",
    "\n",
    "# DFTman imports\n",
    "sys.path.append('../../lib/')\n",
    "import dftmanlib\n",
    "from dftmanlib.pwscf import pwcalculation_helper, pseudo_helper, pseudo_table, PWOutput\n",
    "from dftmanlib.pwscf.pwoutput import fast_patterns\n",
    "from dftmanlib.job import SubmitJob, submitjob_statuses, submit_status\n",
    "from dftmanlib.matproj import mpquery_helper\n",
    "from dftmanlib.db import load_db\n",
    "\n",
    "# Database imports\n",
    "from tinydb import Query, where\n",
    "\n",
    "# Jupyter setup\n",
    "qgrid.enable()\n",
    "%matplotlib notebook\n",
    "\n",
    "# Load database\n",
    "db = load_db()\n",
    "table = db.table('SubmitJob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materials Project Query\n",
    "The first step in any ab-initio calculation is to define the structure which should be simulated.\n",
    "DFTman uses pymatgen `Structure` objects to handle crystal structures, so there are a few convenient ways to load structures into the programming environment:\n",
    "* Manually input structure parameters by calling `pymatgen.Structure`\n",
    "* Load structure from file using `pymatgen.io`\n",
    "* Query for structures using the Materials Project API\n",
    "\n",
    "Querying the Materials Project (MP) is often the simplest and most powerful way to load structures.\n",
    "This process is further simplified by included class and function in DFTmanLib: `MPQuery` and `mpquery_helper`.\n",
    "Queries have 3 required and 1 optional input:\n",
    "* Query criteria which specify properties such as chemistry, and crystal structure\n",
    "* Query parameters which define what information the query returns\n",
    "* API key to authenticate with the Materials Project\n",
    "* Optionally, a postprocessing function which uses Python code to further refine a query in ways which may be difficult or impossible through the standard interface\n",
    "\n",
    "The available criteria and properties are described on the [Materials Project website](https://materialsproject.org/docs/api) and in their [Github repository](https://github.com/materialsproject/mapidoc/tree/master/materials/elasticity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Materials Project API Key\n",
    "MP_API_KEY = 'YOU NEED TO SET THIS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criteria for retrieving FCC Aluminum\n",
    "criteria = {\n",
    "    'elements': {'$in': ['Mo', 'S', 'Se', 'Te']},  # MoX2 TMDs\n",
    "    'spacegroup.number': 194,  # Limit to cubic spacegroup 194\n",
    "    'e_above_hull': {'$lte': 0.0005}  # Get the ground-state structure\n",
    "}\n",
    "# List properties to return\n",
    "properties = ['band_gap', 'elasticity', 'spacegroup.number', 'spacegroup.symbol', 'e_above_hull']\n",
    "# Define a postprocessing function to isolate TMD materials\n",
    "def TMD_postprocess(materials):\n",
    "    # Define desired sets of elements\n",
    "    MoX2_sets = [{'Mo', 'S'}, {'Mo', 'Se'}, {'Mo', 'Te'}]\n",
    "    MoX2_materials = []\n",
    "    for material in materials:\n",
    "        # Keep materials which have desired chemistry\n",
    "        if set(material['elements']) in MoX2_sets:\n",
    "            MoX2_materials.append(material)\n",
    "    return MoX2_materials\n",
    "# Create an MPQuery object using mpquery_helper\n",
    "mp_query = mpquery_helper(criteria, properties, MP_API_KEY,\n",
    "                          postprocess=TMD_postprocess)\n",
    "mp_query.query()  # Run the query\n",
    "mp_query.display()  # Display query results in a pretty table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Calculation\n",
    "After loading an input structure into the programming environment, other parameters must be defined before running a calculation.\n",
    "The availabile input parameters for the DFT package used here, Quantum Espresso PWscf, are listed in the [pw.x input documentation](https://www.quantum-espresso.org/Doc/INPUT_PW.html).\n",
    "\n",
    "DFTmanLib uses `dftmanlib.pwscf` for interacting with pw.x's inputs and outputs.\n",
    "Inputs are handled by `dftmanlib.pwscf.PWInput`, and outputs by `dftmanlib.pwscf.PWOutput`.\n",
    "Entire calculations are represented by the object `dftmanlib.pwscf.PWCalculation`, which is a convenient wrapper around a pair of `PWInput` and `PWOutput` objects.\n",
    "There are a lot of details to directly configuring `PWInput`, `PWOutput`, and `PWCalculation` objects, so some nice helper functions are provided, similar to `mpquery_helper` for `MPQuery` objects.\n",
    "These are `dftmanlib.pwscf.pwinput_helper` and `dftmanlib.pwscf.pwcalculation_helper`. **However, almost always, `pwcalculation_helper` will be most convenient.**\n",
    "\n",
    "Aside from calculation parameters, pseudopotentials are another critical input to DFT calculations, and they are selected by manually creating a `pseudos` dictionary or using `dftmanlib.pwscf.pseudo_helper`, which allows selecting a pseudopotential family from the collection of families provided by DFTman. These include [Standard Solid State Pseudopotentials (SSSP)](https://www.materialscloud.org/discover/sssp/table/efficiency), [Garrity-Bennett-Rabe-Vanderbilt (GBRV)](https://www.physics.rutgers.edu/gbrv/), [PseudoDojo (DOJO)](http://www.pseudo-dojo.org/) potentials with a variety of ultrasoft, norm-conserving; LDA, and GGA exchange-correlation functionals.\n",
    "\n",
    "### Create, Store, and Run `PwCalculation`s using nanoHUB Submit\n",
    "After loading an input structure, finding appropriate pseudopotentials, and configuring calculation parameters, all the necessary components are present to run a DFT calculation. The last step in this process is to create a `Job`, store it in the database, and run it. DFTman provides the following types of `Job`:\n",
    "* `SubmitJob` is used on nanoHUB for remotely submitting to the nanoHUB cluster\n",
    "* `PBSJob` can be used on any cluster running the a Torque PBS system\n",
    "* `LocalJob` runs the calculation locally, e.g. in a nanoHUB workspace, on a cluster workspace, or on a local workstation\n",
    "\n",
    "`Jobs` generally require the following inputs:\n",
    "* A `Calculation` object which has the necessary properties described in `dftmanlib.base`, e.g. `PWCalculation`\n",
    "* Which program to use. This is implemented differently in different types of `Job`.\n",
    "* Resource parameters describing how many processors, nodes, and which queue to run on. These also vary slightly depending on the type of `Job`\n",
    "\n",
    "The best way to figure out what specific inputs a type of `Job` needs is to run `help(JobClass)` where `JobClass` is the type of `Job` you're interested in (e.g. `help(SubmitJob)`)\n",
    "\n",
    "`Jobs` should be automatically stored in the database when they are run, but often when their data are updated, they are **not** automatically updated in the database, to improve performance. Make sure you update jobs in the database by running `job.update()` at critical points in your code, like when you check a job's status or parse its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lat = {\n",
    "    'MoS2': {'a': 3.152,  # ICSD 38401 sg 194\n",
    "             'c': 12.307},\n",
    "    'MoSe2': {'a': 3.2891,  # ICSD 49800 sg 194\n",
    "              'c': 12.9274},\n",
    "    'Te2Mo': {'a': 3.5191,  # ICSD 15431 sg 194\n",
    "              'c': 13.9644}\n",
    "}\n",
    "\n",
    "# Declare a pseudopotential family\n",
    "# available pseudo families:\n",
    "# ['SSSP_EFFICIENCY', 'SSSP_PRECISION', 'GBRV_LDA_US',\n",
    "#  'GBRV_PBE_US', 'GBRV_PBEsol_US', 'DOJO_STANDARD_LDA_NC',\n",
    "#  'DOJO_STANDARD_PBE_NC', 'DOJO_STANDARD_PBEsol_NC',\n",
    "#  'DOJO_STRINGENT_LDA_NC', 'DOJO_STRINGENT_PBE_NC',\n",
    "#  'DOJO_STRINGENT_PBAsol_NC']\n",
    "pseudo_family = 'SSSP_EFFICIENCY'\n",
    "\n",
    "# Declare cutoffs for MoX2 systems\n",
    "# Mo potential requires highest ecutwfc\n",
    "# S potential requires highest ecutrho\n",
    "ecutwfc = 35.0  # Ry\n",
    "ecutrho = ecutwfc * 8.0  # Ry\n",
    "k_dist = 0.20  # 1/A\n",
    "\n",
    "# Initialize a list for the calculations and another for document IDs\n",
    "pw_calculations = []\n",
    "doc_ids = []\n",
    "for material in mp_query.result:\n",
    "    # Iterate over different vdw corrections\n",
    "    for vdw in ['none', 'grimme-d2', 'grimme-d3']:\n",
    "        # Get the structure from the query results\n",
    "        structure = material['structure']\n",
    "        # Shrink the 'c' direction if using vdW corrections\n",
    "        #     for faster calculations\n",
    "        if vdw in ['grimme-d2', 'grimme-d3']:\n",
    "            pymatgen_structure = Structure.from_dict(structure)\n",
    "            c_strain = (exp_lat[material['pretty_formula']]['c'] -\n",
    "                        pymatgen_structure.lattice.c) / pymatgen_structure.lattice.c\n",
    "            pymatgen_structure.apply_strain([0, 0, c_strain])\n",
    "            structure = pymatgen_structure.as_dict()\n",
    "        # Save some parameters for comparison\n",
    "        vdw_corr = vdw\n",
    "        mp_alat = structure['lattice']['a']\n",
    "        mp_clat = structure['lattice']['c']\n",
    "        exp_alat = exp_lat[material['pretty_formula']]['a']\n",
    "        exp_clat = exp_lat[material['pretty_formula']]['c']\n",
    "        # Generate pseudopotentials dictionary\n",
    "        pseudo = pseudo_helper(structure, pseudo_family)\n",
    "\n",
    "        # Declare pw.x inputs\n",
    "        pw_inputs = {\n",
    "            # These are not traditional input cards,\n",
    "            #     but this is the best way to provide\n",
    "            #     them in DFTman\n",
    "            'structure': structure,\n",
    "            'pseudo': pseudo,\n",
    "\n",
    "            # The following mirror traditional pw.x input\n",
    "            #     cards\n",
    "            'control': {\n",
    "                'calculation': 'vc-relax',\n",
    "                'verbosity': 'high',\n",
    "                'disk_io': 'none',\n",
    "                'tstress': True,\n",
    "                'tprnfor': True\n",
    "            },\n",
    "            'system': {\n",
    "                'ibrav': 0,\n",
    "                'ecutwfc': ecutwfc,\n",
    "                'ecutrho': ecutrho,\n",
    "                'occupations': 'fixed',\n",
    "                'vdw_corr': vdw,\n",
    "            },\n",
    "            'electrons': {\n",
    "                'electron_maxstep': 500,\n",
    "                'conv_thr': 1.0e-6\n",
    "            },\n",
    "            'ions': {\n",
    "\n",
    "            },\n",
    "            'cell': {\n",
    "                'cell_factor': 4.0,\n",
    "            },\n",
    "            'kpoints_mode': 'automatic',\n",
    "            'kpoints_grid': (int(round(structure['lattice']['a'] / k_dist)),\n",
    "                             int(round(structure['lattice']['b'] / k_dist)),\n",
    "                             int(round(structure['lattice']['c'] / k_dist))),\n",
    "            'kpoints_shift': (0, 0, 0)\n",
    "        }\n",
    "\n",
    "        # Create a PWCalculation\n",
    "        # additional inputs is a requirement for nanoHUB\n",
    "        #     and should _always_ be equal to list(pseudo.values())\n",
    "        #     for Quantum Espresso pw.x calculations\n",
    "        pw_calculation = pwcalculation_helper(**pw_inputs, \n",
    "            additional_inputs=list(pseudo.values()), job_type='submit')\n",
    "        \n",
    "        submit_job = SubmitJob(calculation=pw_calculation,  # the calculation configured above\n",
    "                               code='espresso-6.2.1_pw',  # QE v6.2.1 on nanoHUB\n",
    "                               walltime='04:00:00',  # 4 hours max run time\n",
    "                               ncpus=12,  # 12 processors requested\n",
    "                               # saving lattice params for comparison\n",
    "                               metadata={'task_id': material['task_id'],\n",
    "                                         'pretty_formula': material['pretty_formula'],\n",
    "                                         'mp_alat': mp_alat,\n",
    "                                         'mp_clat': mp_clat,\n",
    "                                         'exp_alat': exp_alat,\n",
    "                                         'exp_clat': exp_clat})\n",
    "\n",
    "        doc_id = submit_job.run()  # SubmitJob.run() returns the job's database document ID\n",
    "        doc_ids.append(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Jobs from the Database\n",
    "When `Job`s are run, they are automatically stored in the project database, located at `$DFTMAN_ROOT/projects/PROJECT DIRECTORY/db.tinydb`. DFTman uses the [TinyDB module](https://tinydb.readthedocs.io/en/latest/) to manage flat-file JSON-encoded document-based databases. DFTman implements a modified storage protocol based on the [monty module](http://guide.materialsvirtuallab.org/monty/)'s MSON encoder and decoder to automatically convert MSONable python objects to and from serializable python dicationaries. All of this is to say that you can directly store and retrieve Python objects like `Job`s which have `from_dict()` and `as_dict()` methods.\n",
    "\n",
    "The database is organized by tables (think books in an excel document) which are named after the type of thing that they store. For example, the `'SubmitJob'` table stores `SubmitJob`s, and the `'PBSJob'` table stores `PBSJob`s. So, for a project using `SubmitJob`s, the way to load the appropriate database table is the following:\n",
    "```\n",
    "db = load_db()  # This is from dftmanlib.db\n",
    "table = db.table('SubmitJob')\n",
    "```\n",
    "\n",
    "In practice, this is useful for storing input and output information for all `Job`s and `Workflow`s run using DFTman. A lot of information about how to get and query for database entries is listed in the [TinyDB documentation](https://tinydb.readthedocs.io/en/latest/), but the simplest way to load `Job`s into the programming environment from the database is to use the `TinyDB.table.get()` method with a `doc_id` (which is printed and returned whenever something new is added to the database).\n",
    "\n",
    "Any time a project's notebook is shut down, all the variables and data stored in the python environment are lost. So, in order to check on the status of submitted `Job`s or load completed `Job`s and their output, they must be loaded from the database back into the python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = list(range(0, 5))\n",
    "submit_jobs = [table.get(doc_id=doc_id) for doc_id in doc_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch Job Statuses\n",
    "Once `Job`s are run on a remote resource like the nanoHUB cluster using `SubmitJob` or a research cluster using `PBSJob`, it's important to manually watch the status of the `Job` (or at least check it once it has completed) so DFTman knows when it's complete. Other managers use programs called daemons that run in the background to check the status of calculations, but DFTman cannot do this. There are generally three ways to check `Job` statuses:\n",
    "* Queue status functions like `dftmanlib.job.submit_status()` provide information on **currently running** jobs and are the fastest status functions.\n",
    "* Batch status functions like `dftmanlib.job.submitjob_statuses()` which act on a list of `Job` objects provide the status of all `Job`s which they are provided and are the slowest status functions.\n",
    "* Individual status functions `Job.check_status()` which are provided by every `Job` class give the status of an individual `Job` and are useful when running few jobs or checking on specific statuses. \n",
    "\n",
    "Batch and individual status functions often also have the option to automatically update `Job`s in the database after checking their status, but this can be a *very* slow process and should only be done when necessary (i.e. when first checking job statuses and when all jobs are complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queue status\n",
    "submit_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch status\n",
    "submitjob_statuses(submit_jobs, update_in_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Output\n",
    "When `Job`s complete successfully (and often when they complete unsuccessfully), their output can be parsed and brought into the programming environment using `job.parse_output()`. Behind the scenes, this function calls the `Job`'s `calculation.parse_output()` which in turn creates a new instance of the calculation's output class which is passed back up the chain. In the case of Quantum Espresso PWscf, this means creating a `PWOutput` object which provides many of the outputs in the pw.x stdout.\n",
    "\n",
    "`job.parse_output()` always check's if `job.status['status'] == 'Complete'`, so it is important to ensure that `job.check_status()` is called before trying to parse output and that the job is up-to-date in the database.\n",
    "\n",
    "To see the properties provided by `PWOutput`, use `help(PWOutput)` and look under Data Descriptors.\n",
    "To list the entries in `PWOutput.data`, use `display(list(dftmanlib.pwscf.pwoutput.patterns.keys()))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status and parse output if Job is complete\n",
    "for submit_job in submit_jobs:\n",
    "    status = submit_job.check_status(update_in_db=True)\n",
    "    if submit_job.status['status'] == 'Complete':\n",
    "        output = submit_job.parse_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_results = {}\n",
    "for pretty_formula in ['MoS2', 'MoSe2', 'Te2Mo']:\n",
    "    job_query = Query()\n",
    "    jobs = table.search(job_query.metadata.pretty_formula == pretty_formula)\n",
    "    assert len(jobs) > 0\n",
    "    if not lat_results.get(pretty_formula):\n",
    "        meta = jobs[0]['metadata']\n",
    "        lat_result = {\n",
    "            'material_id': meta.get('material_id'),\n",
    "            'pretty_formula': pretty_formula,\n",
    "            'mp_alat': meta.get('mp_alat'),\n",
    "            'mp_clat': meta.get('mp_clat'),\n",
    "            'exp_alat': meta.get('exp_alat'),\n",
    "            'exp_clat': meta.get('exp_clat'),\n",
    "        }\n",
    "        lat_results[pretty_formula] = lat_result\n",
    "    lat_result = lat_results[pretty_formula]\n",
    "    for job in jobs:\n",
    "        vdw = job.input.sections['system'].get('vdw_corr')\n",
    "        try:\n",
    "            output_lattice = job.output.final_structure.lattice\n",
    "        except:\n",
    "            try:\n",
    "                output_lattice = job.output.structures[-1]\n",
    "            except:\n",
    "                print('Job {} {} has no final structure'.format(job.doc_id, job.hash))\n",
    "                print('Sometimes you need to restart the notebook, run the first cell,'\n",
    "                      ' and continue again from here to fix this.')\n",
    "                continue\n",
    "        if vdw == 'none' or vdw is None:\n",
    "            lat_result['dft_alat'] = output_lattice.a\n",
    "            lat_result['dft_clat'] = output_lattice.c\n",
    "        elif vdw == 'grimme-d2':\n",
    "            lat_result['d2_alat'] = output_lattice.a\n",
    "            lat_result['d2_clat'] = output_lattice.c\n",
    "        elif vdw == 'grimme-d3':\n",
    "            lat_result['d3_alat'] = output_lattice.a\n",
    "            lat_result['d3_clat'] = output_lattice.c\n",
    "\n",
    "\n",
    "lat_df = pd.DataFrame(lat_results.values())\n",
    "display(lat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "axmin = lat_df['exp_clat'].min() * 0.98\n",
    "axmax = lat_df['mp_clat'].max() * 1.02\n",
    "\n",
    "plt.plot(np.linspace(axmin, axmax, 10),\n",
    "         np.linspace(axmin, axmax, 10),\n",
    "         label='0% error')\n",
    "plt.plot(np.linspace(axmin, axmax, 10),\n",
    "         np.linspace(axmin, axmax, 10)*1.05,\n",
    "         label='5% error', color='red')\n",
    "plt.plot(np.linspace(axmin, axmax, 10),\n",
    "         np.linspace(axmin, axmax, 10)*0.95,\n",
    "         color='red')\n",
    "\n",
    "plt.scatter(lat_df['exp_clat'], lat_df['mp_clat'], label='Materials Project')\n",
    "plt.scatter(lat_df['exp_clat'], lat_df['dft_clat'], label='DFT')\n",
    "plt.scatter(lat_df['exp_clat'], lat_df['d2_clat'], label='DFT-D2')\n",
    "plt.scatter(lat_df['exp_clat'], lat_df['d3_clat'], label='DFT-D3')\n",
    "\n",
    "plt.xlim(axmin, axmax)\n",
    "plt.ylim(axmin, axmax)\n",
    "\n",
    "plt.xlabel('Experimental c Lattice Parameter')\n",
    "plt.ylabel('Calculated c Lattice Parameter')\n",
    "plt.title('c Lattice Parameter Error in MoX2 TMDs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
